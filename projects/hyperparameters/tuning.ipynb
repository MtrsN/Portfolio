{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Meiryo UI'; font-size: 32px; padding: 25px; text-align: center; color: #ffffff; border-radius: 25px;  font-weight: bold; background-color: #005080;\">üìö Hyperparameter Optimization with the MS-EPSO üê¶</p>\n",
    "\n",
    "## Hyperparameter Optimization Problem\n",
    "\n",
    "Hyperparameter optimization is the process of finding the optimal set of hyperparameters that result in the best performance of a model. This is an important step in the machine learning pipeline as it can lead to significant improvements in model accuracy and generalization.\n",
    "\n",
    "Traditional methods for hyperparameter optimization include:\n",
    "\n",
    "1. **Grid Search**: This method involves exhaustively searching through a manually specified subset of the hyperparameter space. While simple to implement, grid search is computationally expensive and not feasible for large hyperparameter spaces.\n",
    "\n",
    "2. **Bayesian Optimization**: This method builds a probabilistic model of the objective function and uses it to select the most promising hyperparameters to evaluate in the true objective function. While more efficient, it can be complex to implement and computationally intensive.\n",
    "\n",
    "In this project, we will test my published Swarm Intelligence algorithm named [Maximum Search Limitations Evolutionary Particle Swarm Optimization (MS-EPSO)](https://link.springer.com/chapter/10.1007/978-3-030-30241-2_59) for hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "<p style=\"font-family: 'Meiryo UI'; font-size: 30px; padding: 12px; text-align: center; color: #ffffff; border-radius: 15px;  font-weight: bold; background-color: #007040;\">üìö Libraries</p>\n",
    "\n",
    "In this experiment, we will use the XGBoost algorithm as our base model. We will utilize the original implementation of the MS-EPSO algorithm, which can be found [here](https://github.com/MtrsN/MS-EPSO)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from msepso import msepso\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Meiryo UI'; font-size: 30px; padding: 12px; text-align: center; color: #ffffff; border-radius: 15px;  font-weight: bold; background-color: #007040;\">üìä Dataset</p>\n",
    "\n",
    "In this notebook, we will use the Breast Cancer dataset. This dataset is simple and comes pre-processed. We will load the data from the sklearn environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  Target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_breast_cancer()\n",
    "\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "\n",
    "df['Target'] = data.target\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 569 rows and 31 columns\n"
     ]
    }
   ],
   "source": [
    "print(\"The dataset has {} rows and {} columns\".format(df.shape[0], df.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Meiryo UI'; font-size: 30px; padding: 12px; text-align: center; color: #ffffff; border-radius: 15px;  font-weight: bold; background-color: #007040;\">Why MS-EPSO‚ùì</p>\n",
    "\n",
    "In recent years, Optuna has established itself as a valuable hyperparameter optimization framework. This framework allows the implementation of various state-of-the-art optimization methods for tuning machine learning models. Among these techniques, the CMA-ES algorithm is notably included.\n",
    "\n",
    "MS-EPSO was developed to address specific issues found in the Evolutionary Particle Swarm Optimization (EPSO) algorithm. MS-EPSO enhances the balance between exploration (searching through the parameter space) and exploitation (refining the best solutions found). \n",
    "\n",
    "MS-EPSO was initially tailor made for a specific application, but it has proven to be a viable solution for general optimization problems, particularly those where the variables exhibit low standard deviation. For instance, it is highly effective in Feature Selection problems, where the decision is binary (i.e., to include or not include a variable). This makes MS-EPSO an interesting choice for tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Meiryo UI'; font-size: 30px; padding: 12px; text-align: center; color: #ffffff; border-radius: 15px;  font-weight: bold; background-color: #007040;\">üö© The Problem</p>\n",
    "\n",
    "In order to apply MS-EPSO to any problem, we have to define:\n",
    "\n",
    "1. Objective function\n",
    "2. Boundaries\n",
    "3. Algorithm parameters\n",
    "\n",
    "However, the hyperparameter problem requires several settings, not limited to:\n",
    "\n",
    "1. Model\n",
    "2. Model Parameters\n",
    "3. Metric\n",
    "4. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (455, 30), (455,)\n",
      "Validation set: (57, 30), (57,)\n",
      "Test set: (57, 30), (57,)\n"
     ]
    }
   ],
   "source": [
    "'''Split the data into training, validation, and test sets. With a larger dataset, we could check for the possibility to stratify the split based on the target variable. \n",
    "This would ensure that the distribution of the target variable is similar across all the splits. However, in this case, we will keep it simple and split the data randomly.\n",
    "'''\n",
    "\n",
    "RANDOM_SEED = 101\n",
    "\n",
    "X = df.drop('Target', axis=1)\n",
    "y = df['Target']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size= 0.2, random_state=RANDOM_SEED)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size= 0.5, random_state=RANDOM_SEED)\n",
    "\n",
    "print(f'Training set: {X_train.shape}, {y_train.shape}')\n",
    "print(f'Validation set: {X_val.shape}, {y_val.shape}')\n",
    "print(f'Test set: {X_test.shape}, {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Solution:[0.5, 3, 1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1]\n",
      "Example Accuracy:0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "'''Create our objective function based on MS-EPSO parameters and XGBoost performance.'''\n",
    "\n",
    "def objective_function(x):\n",
    "\n",
    "    policy_index = int(x[9])\n",
    "\n",
    "    params = {\n",
    "\n",
    "        'verbosity': 0,\n",
    "        'seed' : RANDOM_SEED,\n",
    "        'eval_metric': 'logloss',\n",
    "\n",
    "        'max_depth': int(x[0]),\n",
    "        'min_child_weight': int(x[1]),\n",
    "        'n_estimators': int(x[2]),\n",
    "        'gamma': x[3],\n",
    "        'subsample': x[4],\n",
    "        'reg_alpha': x[5],\n",
    "        'reg_lambda': x[6],\n",
    "        'learning_rate': x[7],\n",
    "        'colsample_bytree': x[8],\n",
    "        'grow_policy':  ['grow_policy', \"depthwise\", \"lossguide\"][policy_index]\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "\n",
    "    return acc\n",
    "\n",
    "lower_bounds = [0, 1, 500, 1e-9, 0.3, 1e-9, 1e-9, 0.01, 0.3, 0]\n",
    "upper_bounds = [12, 7, 1000, 0.5, 1.0, 100.0, 100.0, 1.0, 1.0, 2]\n",
    "\n",
    "example_solution = [\n",
    "        0.5, # max_depth\n",
    "        3, # min_child_weight\n",
    "        1, # n_estimators\n",
    "        0.5, # gamma\n",
    "        0.5, # subsample\n",
    "        0.5, # reg_alpha\n",
    "        0.5, # reg_lambda\n",
    "        0.5, # learning_rate\n",
    "        0.5, # colsample_bytree\n",
    "        1 # grow_policy\n",
    "]\n",
    "\n",
    "\n",
    "# Test our objective function\n",
    "example_model, example_solution_accuracy = objective_function(example_solution)\n",
    "\n",
    "print(f\"Example Solution:{example_solution}\")\n",
    "print(f\"Example Accuracy:{example_solution_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'update'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m example_solution\u001b[38;5;241m.\u001b[39mupdate(       { \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbosity\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m      2\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m'\u001b[39m : RANDOM_SEED,\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_metric\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogloss\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m XGBClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mexample_solution)\n\u001b[0;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'update'"
     ]
    }
   ],
   "source": [
    "    params = {\n",
    "\n",
    "        'verbosity': 0,\n",
    "        'seed' : RANDOM_SEED,\n",
    "        'eval_metric': 'logloss',\n",
    "\n",
    "        'max_depth': int(example_solution[0]),\n",
    "        'min_child_weight': int(example_solution[1]),\n",
    "        'n_estimators': int(example_solution[2]),\n",
    "        'gamma': example_solution[3],\n",
    "        'subsample': example_solution[4],\n",
    "        'reg_alpha': example_solution[5],\n",
    "        'reg_lambda': v[6],\n",
    "        'learning_rate': x[7],\n",
    "        'colsample_bytree': x[8],\n",
    "        'grow_policy':  ['grow_policy', \"depthwise\", \"lossguide\"][policy_index]\n",
    "    }\n",
    "\n",
    "odel = XGBClassifier(**example_solution)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
